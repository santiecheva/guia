## ğŸ¤– Â¡Manos a la Obra\! GuÃ­a PrÃ¡ctica para Construir tu Chatbot de RRHH con IA Local

**Bienvenido/a al curso de Inteligencia Artificial para RRHH.** Este proyecto te mostrarÃ¡ paso a paso cÃ³mo crear un asistente de chat tipo ChatGPT que funciona **directamente en tu computador** con el modelo **`deepseek-r1:1.5b`**.

-----

### ğŸ’¡ Nuestro Kit de Herramientas

| Componente | Rol (ExplicaciÃ³n para RRHH) | Herramienta |
| :--- | :--- | :--- |
| **El Cerebro** | La inteligencia artificial que piensa y responde. | **deepseek-r1:1.5b** (VÃ­a Ollama) |
| **El Cuerpo** | La interfaz visible donde escribes y lees (la "cara" del chat). | **Streamlit** |
| **El Conector** | El cable o puente que une la interfaz con el cerebro. | **LangChain** |

-----

## âš™ï¸ ETAPA 1: PreparaciÃ³n Inicial (La Caja de Herramientas)

Tranquilo/a: estos pasos solo se hacen **una vez** en tu computador.

### 1.1. Instalar Python

Python es el idioma que usaremos para darle las instrucciones al chatbot.

1.  Entra a: [https://www.python.org/downloads/windows/](https://www.python.org/downloads/windows/)

2.  Descarga la versiÃ³n recomendada.

3.  Abre el instalador.

4.  **âš ï¸ CLAVE:** Marca la casilla **âœ”ï¸ "Add Python to PATH"**.

5.  Haz clic en **Install Now**.

6.  Para verificar, abre el **SÃ­mbolo del sistema** (`cmd`) y escribe:

    ```bash
    python --version
    ```

### 1.2. Instalar Visual Studio Code (VSCode)

VSCode es nuestro "editor" o cuaderno digital para escribir y guardar el cÃ³digo del proyecto.

1.  Ve a: [https://code.visualstudio.com/](https://code.visualstudio.com/)
2.  Descarga la versiÃ³n para Windows e instÃ¡lala con las opciones por defecto.
3.  Ãbrelo al finalizar.

-----

## ğŸŒ³ ETAPA 2: El Taller y los Materiales (Entorno Virtual y LibrerÃ­as)

AquÃ­ crearemos el espacio de trabajo aislado para nuestro chatbot.

### 2.1. Crear una Carpeta de Trabajo

Crea una carpeta en un lugar fÃ¡cil de recordar:

ğŸ“ `C:\Users\tu_usuario\Desktop\chatbot-rh`

### 2.2. Abrir VSCode en esa Carpeta

1.  Abre VSCode.
2.  Arrastra la carpeta `chatbot-rh` dentro del VSCode.

### 2.3. Crear y Activar un Entorno Virtual (`venv`)

El entorno virtual aÃ­sla las librerÃ­as de este proyecto.

1.  Abre la terminal de VSCode (**Terminal \> New Terminal**).

2.  Crea el entorno:

    ```bash
    python -m venv venv
    ```

3.  Activa el entorno:

    ```bash
    venv\Scripts\activate.bat
    ```

    *Si tienes un error, prueba con `venv\Scripts\activate`*

    Si funciona, verÃ¡s **`(venv)`** al inicio de la lÃ­nea.

### 2.4. Instalar los Materiales (LibrerÃ­as)

Con el entorno activado, instalaremos los paquetes de Python necesarios:

```bash
pip install streamlit langchain langchain-ollama python-dotenv ollama
```

-----

## ğŸ§  ETAPA 3: El Cerebro Local (Ollama y `deepseek-r1:1.5b`)

Ollama es la "fÃ¡brica de cerebros" que nos permite usar modelos de IA locales.

### 3.1. Descargar e Instalar Ollama (la FÃ¡brica)

1.  Ve a: [https://ollama.com](https://ollama.com)

2.  Haz clic en **Download for Windows** e instÃ¡lalo con las opciones por defecto.

3.  Ollama se ejecutarÃ¡ en segundo plano automÃ¡ticamente.

### 3.2. Descargar el Modelo `deepseek-r1:1.5b`

Ahora bajaremos el modelo de IA especÃ­fico.

1.  Abre una terminal nueva o usa la de VSCode.

2.  Escribe el comando para descargar el modelo:

    ```bash
    ollama pull deepseek-r1:1.5b
    ```

    *La primera vez tardarÃ¡ varios minutos.*

### 3.3. Probar el Modelo (Opcional)

Solo para confirmar que el cerebro funciona, chatea un momento con Ã©l. Para salir, presiona **Ctrl + C**.

```bash
ollama run deepseek-r1:1.5b
```

-----

## ğŸ¨ ETAPA 4: El Cuerpo (Interfaz con Streamlit)

Creamos la "cara" del chatbot.

### 4.1. Crear el archivo `app.py` (Demo)

En VSCode, crea un archivo llamado:

ğŸ“„ `app.py`

Y pega el siguiente cÃ³digo. En esta etapa, el chatbot solo muestra la interfaz y una respuesta de **demostraciÃ³n** (aÃºn no llama a la IA).

```python
import streamlit as st

# ğŸ¨ ConfiguraciÃ³n bÃ¡sica de la pÃ¡gina
st.set_page_config(
    page_title="Chatbot RH",
    page_icon="ğŸ¤–",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ğŸ§¼ CSS: fondo negro + letra blanca
st.markdown(
    """
    <style>
    /* Fondo negro */
    .stApp {
        background-color: #000000 !important;
        color: #ffffff !important;
    }

    /* Texto general en blanco */
    * {
        color: #ffffff !important;
    }

    /* Ocultar menÃº y pie de pÃ¡gina de Streamlit */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}

    /* Ajustar el ancho del contenedor principal */
    .block-container {
        max-width: 900px;
        padding-top: 2rem;
        padding-bottom: 2rem;
    }

    /* TÃ­tulos centrados y blancos */
    h1, h2, h3, h4, h5, h6 {
        text-align: center;
        color: #ffffff !important;
    }

    /* Sidebar oscuro */
    section[data-testid="stSidebar"] {
        background-color: #111111 !important;
    }

    /* CÃ³digo dentro del sidebar */
    .stCode, code {
        color: #ffffff !important;
        background-color: #222222 !important;
    }

    /* Chat bubbles */
    .stChatMessage {
        background-color: #111111 !important;
        color: #ffffff !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ğŸ§  Estado de la conversaciÃ³n (Mensaje de bienvenida)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": (
                "ğŸ‘‹ Â¡Hola! Soy tu Chatbot de Recursos Humanos.\n\n"
                "Puedo ayudarte con cosas como:\n"
                "- PolÃ­ticas de vacaciones ğŸ–ï¸\n"
                "- Beneficios y bienestar ğŸ\n"
                "- Procesos de selecciÃ³n ğŸ§‘â€ğŸ’¼\n"
                "- Onboarding de nuevas personas ğŸš€\n\n"
                "CuÃ©ntame, Â¿quÃ© te gustarÃ­a saber hoy?"
            ),
        }
    ]

# ğŸ§± Encabezado principal
st.title("ğŸ¤– Chatbot para Recursos Humanos")
st.caption("Tu asistente amigable de RRHH â€“ cero tecnicismos, respuestas claras y un toque de humor ğŸ˜„")

# ğŸ¯ Sidebar con informaciÃ³n extra
with st.sidebar:
    st.subheader("Acerca de este chatbot")
    st.write(
        """
        Este asistente estÃ¡ pensado para:
        - Responder preguntas frecuentes de RRHH  
        - Servir como ejemplo en un curso de IA  
        - Mostrar cÃ³mo se ve un chat tipo ChatGPT con Streamlit  
        """
    )
    st.markdown("---")
    st.write("ğŸ’¡ Tip: prueba con preguntas como:")
    st.code("Â¿CuÃ¡ntos dÃ­as de vacaciones tengo al aÃ±o?")
    st.code("Â¿CÃ³mo es el proceso de onboarding?")

# ğŸ¤¹ Respuesta demo (FunciÃ³n de demostraciÃ³n, no usa la IA)
def generar_respuesta_demo(pregunta: str) -> str:
    respuesta = f"""
He recibido tu pregunta:

> *{pregunta}*

ğŸ” **VersiÃ³n demo:** aquÃ­ irÃ­a la respuesta inteligente del modelo de IA.

Mientras conectamos el modelo real (`deepseek-r1:1.5b`), podemos imaginar que ya soy sÃºper listo ğŸ˜„
"""
    return respuesta

# ğŸ’¬ Mostrar historial del chat
for msg in st.session_state.messages:
    avatar = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ§‘â€ğŸ’¼"
    with st.chat_message("assistant" if msg["role"] == "assistant" else "user", avatar=avatar):
        st.markdown(msg["content"])

# ğŸ§¾ Input del usuario
prompt = st.chat_input("Escribe tu pregunta sobre Recursos Humanos aquÃ­...")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’¼"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("Pensando la mejor respuesta para ti... ğŸ’­"):
            respuesta = generar_respuesta_demo(prompt)
            st.markdown(respuesta)
    st.session_state.messages.append({"role": "assistant", "content": respuesta})
```

### 4.2. Probar la Interfaz

En la terminal de VSCode (con el entorno activado `(venv)`), ejecuta:

```bash
streamlit run app.py
```

Se abrirÃ¡ un navegador con tu interfaz.

-----

## ğŸ”Œ ETAPA 5: ConexiÃ³n Final (El Chatbot Funcional)

Unimos el **Cuerpo (Streamlit)** con el **Cerebro (deepseek-r1:1.5b vÃ­a LangChain)**.

### 5.1. Reemplazar el cÃ³digo de `app.py`

Abre `app.py` y **reemplaza TODO el contenido** por este cÃ³digo final. AquÃ­ se aÃ±ade la lÃ³gica de LangChain para interactuar con Ollama.

```python
import streamlit as st
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage


# ğŸ¨ ConfiguraciÃ³n bÃ¡sica de la pÃ¡gina
st.set_page_config(
    page_title="Chatbot RH",
    page_icon="ğŸ¤–",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ğŸ§¼ CSS: fondo negro + letra blanca
st.markdown(
    """
    <style>
    /* Fondo negro */
    .stApp {
        background-color: #000000 !important;
        color: #ffffff !important;
    }

    /* Texto general en blanco */
    * {
        color: #ffffff !important;
    }

    /* Ocultar menÃº y pie de pÃ¡gina de Streamlit */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}

    /* Ajustar el ancho del contenedor principal */
    .block-container {
        max-width: 900px;
        padding-top: 2rem;
        padding-bottom: 2rem;
    }

    /* TÃ­tulos centrados y blancos */
    h1, h2, h3, h4, h5, h6 {
        text-align: center;
        color: #ffffff !important;
    }

    /* Sidebar oscuro */
    section[data-testid="stSidebar"] {
        background-color: #111111 !important;
    }

    /* CÃ³digo dentro del sidebar */
    .stCode, code {
        color: #ffffff !important;
        background-color: #222222 !important;
    }

    /* Chat bubbles */
    .stChatMessage {
        background-color: #111111 !important;
        color: #ffffff !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ğŸ§  Estado de la conversaciÃ³n (Mensaje de bienvenida)
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": (
                "ğŸ‘‹ Â¡Hola! Soy tu Chatbot de Recursos Humanos.\n\n"
                "Puedo ayudarte con cosas como:\n"
                "- PolÃ­ticas de vacaciones ğŸ–ï¸\n"
                "- Beneficios y bienestar ğŸ\n"
                "- Procesos de selecciÃ³n ğŸ§‘â€ğŸ’¼\n"
                "- Onboarding de nuevas personas ğŸš€\n\n"
                "CuÃ©ntame, Â¿quÃ© te gustarÃ­a saber hoy?"
            ),
        }
    ]

# ğŸ§± Encabezado principal
st.title("ğŸ¤– Chatbot para Recursos Humanos")
st.caption("Tu asistente amigable de RRHH â€“ cero tecnicismos, respuestas claras y un toque de humor ğŸ˜„")

# ğŸ¯ Sidebar con informaciÃ³n extra
with st.sidebar:
    st.subheader("Acerca de este chatbot")
    st.write(
        """
        Este asistente estÃ¡ pensado para:
        - Responder preguntas frecuentes de RRHH  
        - Servir como ejemplo en un curso de IA  
        - Mostrar cÃ³mo se ve un chat tipo ChatGPT con Streamlit  
        """
    )
    st.markdown("---")
    st.write("ğŸ’¡ Tip: prueba con preguntas como:")
    st.code("Â¿CuÃ¡ntos dÃ­as de vacaciones tengo al aÃ±o?")
    st.code("Â¿CÃ³mo es el proceso de onboarding?")

# --- FUNCIONES CLAVE DE LA IA ---

# 1. FunciÃ³n para cargar el modelo de Ollama
@st.cache_resource
def cargar_modelo():
    # Modelo local y gratuito usando Ollama
    modelo = ChatOllama(
        # Â¡IMPORTANTE! Usamos el modelo deepseek-r1:1.5b que descargamos en la Etapa 3.
        model="deepseek-r1:1.5b",    
        temperature=0.2          # QuÃ© tan creativo es (0 = muy serio, 1 = muy creativo)
    )
    return modelo

# 2. FunciÃ³n que envÃ­a la pregunta al modelo e incluye el historial
def responder_pregunta(pregunta: str) -> str:
    modelo = cargar_modelo()
    
    # ğŸ“ Creamos el "contexto" o historial
    mensajes = [
        SystemMessage(content="Eres un asistente amigable de Recursos Humanos. Responde en espaÃ±ol, de forma clara, con cero tecnicismos y un tono servicial. CÃ©ntrate solo en temas de RRHH."),
    ]
    
    # AÃ±adimos los mensajes del historial
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            mensajes.append(HumanMessage(content=msg["content"]))
        elif msg["role"] == "assistant":
            # Excluimos el mensaje de bienvenida inicial
            if "Â¡Hola!" not in msg["content"]: 
                mensajes.append(AIMessage(content=msg["content"]))
    
    # El Ãºltimo mensaje siempre es la pregunta actual
    mensajes.append(HumanMessage(content=pregunta))

    # ğŸš€ Llamamos al cerebro (al modelo)
    respuesta = modelo.invoke(mensajes)
    return respuesta.content

# -----------------------------------


# ğŸ’¬ Mostrar historial del chat
for msg in st.session_state.messages:
    avatar = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ§‘â€ğŸ’¼"
    with st.chat_message("assistant" if msg["role"] == "assistant" else "user", avatar=avatar):
        st.markdown(msg["content"])

# ğŸ§¾ Input del usuario
prompt = st.chat_input("Escribe tu pregunta sobre Recursos Humanos aquÃ­...")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’¼"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("Pensando la mejor respuesta para ti... ğŸ’­"):
            # Â¡AquÃ­ llamamos a la IA real!
            respuesta = responder_pregunta(prompt)
            st.markdown(respuesta)
    st.session_state.messages.append({"role": "assistant", "content": respuesta})
```

### 5.2. Ejecutar el Chatbot

AsegÃºrate de que **Ollama estÃ¡ corriendo** en segundo plano. En la terminal, ejecuta de nuevo:

```bash
streamlit run app.py
```

-----

## ğŸ¯ Â¿QuÃ© puedes hacer ahora? (PrÃ³ximos Pasos)

âœ” **Cambiar el Rol:** Modifica el `SystemMessage` para especializar al chatbot.
âœ” **Agregar Contexto:** Investiga cÃ³mo usar LangChain con **RAG** para que el chatbot pueda leer **documentos internos** de RRHH.
âœ” **Ajustar el Modelo:** Experimenta cambiando el valor de `temperature` para un tono mÃ¡s formal o mÃ¡s creativo.

-----
