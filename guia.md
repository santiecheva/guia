La estructura de la guÃ­a serÃ¡:

1. **Instalar herramientas bÃ¡sicas (Windows).**
2. **Crear un entorno virtual y preparar el proyecto.**
3. **Construir la interfaz con Streamlit.**
4. **Crear el modelo de IA con LangChain.**
5. **Conectar la interfaz con el modelo para tener un chatbot funcional.**

---

# ğŸ§  **GUÃA COMPLETA PARA CREAR UN CHATBOT CON LANGCHAIN + STREAMLIT**

---

---

# 1. ğŸ› ï¸ **InstalaciÃ³n de Herramientas en Windows**

Tranquilo/a: estos pasos son mÃ¡s tÃ©cnicos, pero solo se hacen **una vez**.

---

## 1.1. **Instalar Python**

1. Entra a: [https://www.python.org/downloads/windows/](https://www.python.org/downloads/windows/)
2. Descarga la versiÃ³n recomendada (normalmente aparece como *â€œDownload Python 3.x.xâ€*).
3. Abre el instalador.
4. **IMPORTANTE**: marca la casilla
   âœ”ï¸ **"Add Python to PATH"**
5. Haz clic en **Install Now**.
6. Espera 1â€“2 minutos a que termine.

Para verificar que quedÃ³ bien instalado:

* Abre el **SÃ­mbolo del sistema** (Windows + buscar â€œcmdâ€).
* Escribe:

```
python --version
```

Debe aparecer algo como `Python 3.x.x`.


---
<img width="1160" height="581" alt="image" src="https://github.com/user-attachments/assets/8433998c-ac35-4576-bc31-5c28e9666016" />


## 1.2. **Instalar Visual Studio Code (VSCode)**

VSCode serÃ¡ tu "editor" para escribir el proyecto.

1. Ir a: [https://code.visualstudio.com/](https://code.visualstudio.com/)
2. Descargar versiÃ³n para Windows.
3. Instalar con opciones por defecto.
4. Abrir VSCode al final.
<img width="1600" height="863" alt="image" src="https://github.com/user-attachments/assets/2c346a31-492b-44ea-bacd-8beed3759125" />

---

# 2. ğŸ§ª **Crear un Entorno Virtual (Recomendado)**

Un **entorno virtual** es una carpeta que guarda todas las librerÃ­as que tu chatbot va a usar.
AsÃ­ no daÃ±a otros programas del computador.

---

## 2.1. Crear una carpeta de trabajo

Crea una carpeta en tu escritorio:

ğŸ“ `C:\Users\tu_usuario\Desktop\chatbot-rh`

<img width="212" height="198" alt="image" src="https://github.com/user-attachments/assets/e8237e0b-464d-4525-b3c8-7a2e122760cd" />



---

## 2.2. Abrir VSCode en esa carpeta

1. Abre VSCode.
2. Arrastra la carpeta dentro del VSCode.
   (o usa **File > Open Folder**)

<img width="1600" height="861" alt="image" src="https://github.com/user-attachments/assets/e312ddb2-be49-4379-a1fa-1758e127cdf0" />


---

## 2.3. Crear un entorno virtual

Dentro de VSCode abre la terminal:
**Terminal > New Terminal**

Escribe:

```
python -m venv venv
```

Esto crearÃ¡ una carpeta llamada **venv**.

<img width="1275" height="978" alt="image" src="https://github.com/user-attachments/assets/da399180-eb60-404c-8d88-f5aa1f13827f" />

---

## 2.4. Activar el entorno

En la misma terminal escribe:

```
venv\Scripts\activate.bat
```
<img width="1292" height="957" alt="image" src="https://github.com/user-attachments/assets/80fe2f48-97ca-4c9c-ac57-6f6b46637ba7" />


si tienes algÃ¹n error, por ejemplo un mensaje en rojo, ejecuta el comando asÃ­:

```
venv\Scripts\activate
```

Si funciona, verÃ¡s algo asÃ­:

```
(venv) C:\Users\...
```

---

---

# 3. ğŸ“¦ **Instalar las LibrerÃ­as Necesarias**

Con el entorno activado, instala:

<img width="1448" height="981" alt="image" src="https://github.com/user-attachments/assets/7af4e76f-3393-4161-8759-0bfdb1ee5020" />


```
pip install streamlit langchain langchain-ollama python-dotenv ollama

```



---

---

# 4. ğŸ¨ **Crear la Interfaz con Streamlit (PASO 1)**

Vamos a crear primero **lo que las personas verÃ¡n**, antes del cerebro del chatbot.

En VSCode dentro de la carpeta que estÃ s trabajando,  crea un archivo llamado:

ğŸ“„ `app.py`


<img width="1600" height="855" alt="image" src="https://github.com/user-attachments/assets/9cec2cc1-6e8b-4944-a96d-ddd97c2ae70a" />


Y pega esto:

```python
import streamlit as st

# ğŸ¨ ConfiguraciÃ³n bÃ¡sica de la pÃ¡gina
st.set_page_config(
    page_title="Chatbot RH",
    page_icon="ğŸ¤–",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ğŸ§¼ Un poco de CSS para que se vea mÃ¡s pro (tipo chat)
st.markdown(
    """
    <style>
    /* Fondo suave tipo app moderna */
    .stApp {
        background: linear-gradient(135deg, #f3f4ff 0%, #eef9ff 50%, #fff8ff 100%);
    }

    /* Ocultar menÃº y pie de pÃ¡gina de Streamlit */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}

    /* Ajustar el ancho del contenedor principal */
    .block-container {
        max-width: 900px;
        padding-top: 2rem;
        padding-bottom: 2rem;
    }

    /* TÃ­tulo centrado */
    h1 {
        text-align: center;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ğŸ§  Estado de la conversaciÃ³n
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "assistant",
            "content": (
                "ğŸ‘‹ Â¡Hola! Soy tu *Chatbot de Recursos Humanos*.\n\n"
                "Puedo ayudarte con cosas como:\n"
                "- PolÃ­ticas de vacaciones ğŸ–ï¸\n"
                "- Beneficios y bienestar ğŸ\n"
                "- Procesos de selecciÃ³n ğŸ§‘â€ğŸ’¼\n"
                "- Onboarding de nuevas personas ğŸš€\n\n"
                "CuÃ©ntame, Â¿quÃ© te gustarÃ­a saber hoy?"
            ),
        }
    ]

# ğŸ§± Encabezado principal
st.title("ğŸ¤– Chatbot para Recursos Humanos")
st.caption("Tu asistente amigable de RRHH â€“ cero tecnicismos, respuestas claras y un toque de humor ğŸ˜„")

# ğŸ¯ Sidebar con informaciÃ³n extra (opcional)
with st.sidebar:
    st.subheader("Acerca de este chatbot")
    st.write(
        """
        Este asistente estÃ¡ pensado para:
        - Responder preguntas frecuentes de RRHH  
        - Servir como ejemplo en un curso de IA  
        - Mostrar cÃ³mo se ve un chat tipo ChatGPT con Streamlit  
        """
    )
    st.markdown("---")
    st.write("ğŸ’¡ *Tip:* prueba con preguntas como:")
    st.code("Â¿CuÃ¡ntos dÃ­as de vacaciones tengo al aÃ±o?")
    st.code("Â¿CÃ³mo es el proceso de onboarding?")

# ğŸ¤¹ FunciÃ³n de respuesta DEMO (luego aquÃ­ conectas tu modelo real)
def generar_respuesta_demo(pregunta: str) -> str:
    # Esta respuesta es solo para que el chat se vea vivo.
    # AquÃ­ luego puedes llamar a tu modelo con LangChain + Ollama.
    respuesta = f"""
He recibido tu pregunta:

> **{pregunta}**

ğŸ” *VersiÃ³n demo:* aquÃ­ irÃ­a la respuesta inteligente del modelo de IA.

Como soy un bot de RRHH en modo demostraciÃ³n, te puedo decir algo general:

- RevisarÃ­a las polÃ­ticas internas relacionadas con este tema.
- Te darÃ­a una explicaciÃ³n clara y en lenguaje sencillo.
- Si aplica, te indicarÃ­a con quiÃ©n podrÃ­as hablar en RRHH para mÃ¡s detalle.

Mientras conectas el modelo real, podemos imaginar que ya soy sÃºper listo ğŸ˜„
"""
    return respuesta

# ğŸ’¬ Mostrar historial de mensajes
for msg in st.session_state.messages:
    avatar = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ§‘â€ğŸ’¼"
    with st.chat_message("assistant" if msg["role"] == "assistant" else "user", avatar=avatar):
        st.markdown(msg["content"])

# ğŸ§¾ Caja de entrada tipo ChatGPT
prompt = st.chat_input("Escribe tu pregunta sobre Recursos Humanos aquÃ­...")

if prompt:
    # 1) Agregamos el mensaje del usuario al historial
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘â€ğŸ’¼"):
        st.markdown(prompt)

    # 2) Generamos la respuesta (demo o modelo real)
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        with st.spinner("Pensando la mejor respuesta para ti... ğŸ’­"):
            respuesta = generar_respuesta_demo(prompt)
            st.markdown(respuesta)
    st.session_state.messages.append({"role": "assistant", "content": respuesta})

```

<img width="1267" height="973" alt="image" src="https://github.com/user-attachments/assets/80d5d110-5084-49db-99b2-9204e888775a" />


Para probar la interfaz:

<img width="1127" height="976" alt="image" src="https://github.com/user-attachments/assets/bbc7ec39-8b19-4b73-a7e1-325484954e64" />


En la terminal (con el entorno activado):

```
streamlit run app.py
```

Se abrirÃ¡ un navegador con tu interfaz âœ¨

<img width="1600" height="729" alt="image" src="https://github.com/user-attachments/assets/f4f94a38-1801-42d0-a227-26cef4e832f5" />

---


# 5. ğŸª **Instalar Ollama y Descargar el Modelo (ANTES DE CONECTAR EL CHATBOT)**

Ollama es el programa que permite tener modelos de IA **locales y gratuitos** en tu computador.
Piensa en Ollama como â€œla fÃ¡brica de cerebrosâ€ donde vas a descargar el modelo que usarÃ¡ el chatbot.

---

## 5.1. Descargar e instalar Ollama

1. Ve a: [https://ollama.com](https://ollama.com)
2. Haz clic en **Download for Windows**.
3. Abre el instalador (`Ollama Setup.exe`) y sigue los pasos por defecto (Siguiente, Siguienteâ€¦).
4. Cuando termine, Ollama quedarÃ¡ instalado y normalmente se ejecuta solo en segundo plano.

<img width="1600" height="855" alt="image" src="https://github.com/user-attachments/assets/05787bd3-347a-4379-b1b3-5c25c5fd781c" />
<img width="1600" height="829" alt="image" src="https://github.com/user-attachments/assets/b9374ede-5340-433a-8001-a798f3bee654" />

<img width="872" height="661" alt="image" src="https://github.com/user-attachments/assets/330bdabe-bbbf-49af-87d4-8cbf80134577" />

---

## 5.2. Verificar que Ollama funciona

1. Abre el **SÃ­mbolo del sistema** (cmd) o una terminal nueva.
2. Escribe:

```bash
ollama --version
```

Si todo estÃ¡ bien, verÃ¡s un nÃºmero de versiÃ³n (por ejemplo `0.3.x`).
Si ves â€œcommand not foundâ€ o similar, asegÃºrate de cerrar y abrir de nuevo la terminal o reiniciar el equipo.

---

## 5.3. Descargar (hacer *pull*) del modelo `llama3.1`

Ahora vamos a **bajar el modelo de IA** que usarÃ¡ el chatbot.
En la misma terminal escribe:

```bash
ollama pull llama3.1
```

* La **primera vez** puede tardar varios minutos (estÃ¡ descargando el modelo).
* Solo tienes que hacerlo **una vez**. DespuÃ©s ya queda guardado.

---

## 5.4. Probar el modelo rÃ¡pidamente (opcional)

Solo para ver que funciona:

```bash
ollama run llama3.1
```

Escribe algo como:

> Hola, Â¿quÃ© puedes hacer?

Te responderÃ¡ en la misma terminal.
Para salir, presiona **Ctrl + C**.

Con esto ya tienes:

âœ… Ollama instalado
âœ… Modelo `llama3.1` descargado y listo para usar

Ahora sÃ­, vamos a conectar **Streamlit + LangChain + Ollama**.

---

# 6. ğŸ”Œ **Conectar la Interfaz con el Modelo (PASO FINAL)**

Ahora vamos a unir todo en **un solo archivo `app.py`**:

* La interfaz (Streamlit).
* El modelo (Ollama vÃ­a LangChain).
* La lÃ³gica para responder preguntas.

Abre `app.py` y **reemplaza todo el contenido** por este:

```python
import streamlit as st
from langchain_ollama import ChatOllama

# 1. ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(page_title="Chatbot RH", page_icon="ğŸ¤–")

st.title("ğŸ¤– Chatbot para Recursos Humanos")
st.write("Haz tus preguntas sobre procesos de talento humano, cultura, bienestar, etc.")

# 2. FunciÃ³n para cargar el modelo de Ollama
@st.cache_resource
def cargar_modelo():
    # Modelo local y gratuito usando Ollama
    modelo = ChatOllama(
        model="llama3.1",   # nombre del modelo que bajaste con `ollama pull`
        temperature=0.2     # quÃ© tan creativo es (0 = muy serio, 1 = muy creativo)
    )
    return modelo

# 3. FunciÃ³n que envÃ­a la pregunta al modelo
def responder_pregunta(pregunta: str) -> str:
    modelo = cargar_modelo()
    respuesta = modelo.invoke(pregunta)
    return respuesta.content

# 4. Interfaz de Streamlit
pregunta = st.text_input("âœï¸ Escribe tu pregunta aquÃ­:")

if st.button("Enviar"):
    if pregunta.strip() == "":
        st.warning("Por favor escribe una pregunta.")
    else:
        with st.spinner("Pensando la mejor respuesta..."):
            respuesta = responder_pregunta(pregunta)
        st.success("Respuesta del chatbot:")
        st.write(respuesta)
```

Puntos clave para explicar a alguien de RRHH:

* `cargar_modelo()` ğŸ‘‰ es donde definimos quÃ© modelo usamos (`llama3.1`).
* `responder_pregunta()` ğŸ‘‰ es la funciÃ³n que envÃ­a la pregunta al modelo y devuelve la respuesta.
* La parte de **Streamlit** (abajo) muestra el cuadro de texto, el botÃ³n y la respuesta.

---

# 7. â–¶ï¸ **Ejecutar el chatbot**

En la terminal escribe:

```
streamlit run app.py
```

Y tendrÃ¡s un chatbot funcional:

* bonito
* usable
* pensado para personas sin conocimientos tÃ©cnicos
* funcionando con LangChain + OpenAI
* con interfaz sencilla en Streamlit

---

# 8. ğŸ¯ Â¿QuÃ© puedes hacer ahora?

âœ” Cambiar el rol del chatbot (RRHH, bienestar, cultura, selecciÃ³n).
âœ” Agregar contexto (manual del empleado, polÃ­ticas internas).
âœ” Guardar conversaciones.
âœ” Convertirlo en una app web.
âœ” Integrarlo en Teams o Slack.


---






