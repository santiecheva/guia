La estructura de la guÃ­a serÃ¡:

1. **Instalar herramientas bÃ¡sicas (Windows).**
2. **Crear un entorno virtual y preparar el proyecto.**
3. **Construir la interfaz con Streamlit.**
4. **Crear el modelo de IA con LangChain.**
5. **Conectar la interfaz con el modelo para tener un chatbot funcional.**

---

# ğŸ§  **GUÃA COMPLETA PARA CREAR UN CHATBOT CON LANGCHAIN + STREAMLIT**

---

---

# 1. ğŸ› ï¸ **InstalaciÃ³n de Herramientas en Windows**

Tranquilo/a: estos pasos son mÃ¡s tÃ©cnicos, pero solo se hacen **una vez**.

---

## 1.1. **Instalar Python**

1. Entra a: [https://www.python.org/downloads/windows/](https://www.python.org/downloads/windows/)
2. Descarga la versiÃ³n recomendada (normalmente aparece como *â€œDownload Python 3.x.xâ€*).
3. Abre el instalador.
4. **IMPORTANTE**: marca la casilla
   âœ”ï¸ **"Add Python to PATH"**
5. Haz clic en **Install Now**.
6. Espera 1â€“2 minutos a que termine.

Para verificar que quedÃ³ bien instalado:

* Abre el **SÃ­mbolo del sistema** (Windows + buscar â€œcmdâ€).
* Escribe:

```
python --version
```

Debe aparecer algo como `Python 3.x.x`.


---
<img width="1160" height="581" alt="image" src="https://github.com/user-attachments/assets/8433998c-ac35-4576-bc31-5c28e9666016" />


## 1.2. **Instalar Visual Studio Code (VSCode)**

VSCode serÃ¡ tu "editor" para escribir el proyecto.

1. Ir a: [https://code.visualstudio.com/](https://code.visualstudio.com/)
2. Descargar versiÃ³n para Windows.
3. Instalar con opciones por defecto.
4. Abrir VSCode al final.
<img width="1600" height="863" alt="image" src="https://github.com/user-attachments/assets/2c346a31-492b-44ea-bacd-8beed3759125" />

---

# 2. ğŸ§ª **Crear un Entorno Virtual (Recomendado)**

Un **entorno virtual** es una carpeta que guarda todas las librerÃ­as que tu chatbot va a usar.
AsÃ­ no daÃ±a otros programas del computador.

---

## 2.1. Crear una carpeta de trabajo

Crea una carpeta en tu escritorio:

ğŸ“ `C:\Users\tu_usuario\Desktop\chatbot-rh`

<img width="212" height="198" alt="image" src="https://github.com/user-attachments/assets/e8237e0b-464d-4525-b3c8-7a2e122760cd" />



---

## 2.2. Abrir VSCode en esa carpeta

1. Abre VSCode.
2. Arrastra la carpeta dentro del VSCode.
   (o usa **File > Open Folder**)

<img width="1600" height="861" alt="image" src="https://github.com/user-attachments/assets/e312ddb2-be49-4379-a1fa-1758e127cdf0" />


---

## 2.3. Crear un entorno virtual

Dentro de VSCode abre la terminal:
**Terminal > New Terminal**

Escribe:

```
python -m venv venv
```

Esto crearÃ¡ una carpeta llamada **venv**.

---

## 2.4. Activar el entorno

En la misma terminal escribe:

```
venv\Scripts\activate
```

Si funciona, verÃ¡s algo asÃ­:

```
(venv) C:\Users\...
```

---

---

# 3. ğŸ“¦ **Instalar las LibrerÃ­as Necesarias**

Con el entorno activado, instala:

```
pip install streamlit langchain langchain-openai python-dotenv
```

Si deseas usar **OpenAI**, instala tambiÃ©n:

```
pip install openai
```

---

---

# 4. ğŸ¨ **Crear la Interfaz con Streamlit (PASO 1)**

Vamos a crear primero **lo que las personas verÃ¡n**, antes del cerebro del chatbot.

En VSCode crea un archivo llamado:

ğŸ“„ `app.py`

Y pega esto:

```python
import streamlit as st

st.set_page_config(page_title="Chatbot RH", page_icon="ğŸ¤–")

st.title("ğŸ¤– Chatbot para Recursos Humanos")

# Ãrea donde el usuario escribe su pregunta
pregunta = st.text_input("Escribe tu pregunta aquÃ­:")

# BotÃ³n
if st.button("Enviar"):
    if pregunta.strip() == "":
        st.warning("Por favor escribe una pregunta.")
    else:
        st.write("ğŸ’¬ Respuesta del modelo aparecerÃ¡ aquÃ­...")
```

Para probar la interfaz:

En la terminal (con el entorno activado):

```
streamlit run app.py
```

Se abrirÃ¡ un navegador con tu interfaz âœ¨

---

---

# 5. ğŸ§  **Crear el Modelo con LangChain (PASO 2)**

Ahora crearemos â€œel cerebroâ€ del chatbot.

Crea un archivo:

ğŸ“„ `modelo.py`

Y pega esto:

```python
import os
from langchain_openai import ChatOpenAI

def cargar_modelo():
    # Modelo base
    modelo = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.2
    )
    return modelo

def responder_pregunta(pregunta):
    modelo = cargar_modelo()

    respuesta = modelo.invoke(pregunta)

    return respuesta.content
```

IMPORTANTE:
Crea un archivo **.env** con tu API key de OpenAI:

ğŸ“„ `.env`

```
OPENAI_API_KEY=tu_api_key
```

*Tu API Key se consigue en [https://platform.openai.com](https://platform.openai.com)*

---

---

# 6. ğŸ”Œ **Conectar la Interfaz con el Modelo (PASO FINAL)**

Ahora vuelve a abrir `app.py`
y cÃ¡mbialo por esta versiÃ³n:

```python
from langchain_ollama import ChatOllama

def cargar_modelo():
    # Modelo local y gratuito usando Ollama
    modelo = ChatOllama(
        model="llama3.1",   # nombre del modelo que bajaste con `ollama pull`
        temperature=0.2
    )
    return modelo

def responder_pregunta(pregunta: str) -> str:
    modelo = cargar_modelo()

    # Igual que antes, invoke devuelve un mensaje con .content
    respuesta = modelo.invoke(pregunta)

    return respuesta.content
```

---

---

# 7. â–¶ï¸ **Ejecutar el chatbot**

En la terminal escribe:

```
streamlit run app.py
```

Y tendrÃ¡s un chatbot funcional:

* bonito
* usable
* pensado para personas sin conocimientos tÃ©cnicos
* funcionando con LangChain + OpenAI
* con interfaz sencilla en Streamlit

---

# 8. ğŸ¯ Â¿QuÃ© puedes hacer ahora?

âœ” Cambiar el rol del chatbot (RRHH, bienestar, cultura, selecciÃ³n).
âœ” Agregar contexto (manual del empleado, polÃ­ticas internas).
âœ” Guardar conversaciones.
âœ” Convertirlo en una app web.
âœ” Integrarlo en Teams o Slack.

Si quieres, te puedo ayudar a:

ğŸ‘‰ agregar memoria
ğŸ‘‰ agregar documentos PDF para que responda sobre ellos
ğŸ‘‰ hacerlo multilingÃ¼e
ğŸ‘‰ ponerlo en la nube (AWS, Azure o GCP)

---

